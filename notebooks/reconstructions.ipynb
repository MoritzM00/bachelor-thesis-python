{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drcomp.reducers import PCA, AutoEncoder\n",
    "from drcomp.autoencoder import FullyConnectedAE\n",
    "from drcomp.utils.notebooks import get_dataset, get_model_for_dataset, get_preprocessor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from skorch.callbacks import EarlyStopping, LRScheduler\n",
    "from drcomp.plotting import (\n",
    "    compare_metrics,\n",
    "    plot_reconstructions,\n",
    "    visualize_2D_latent_space,\n",
    "    save_fig,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "plt.style.use(\"science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"..\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Emotion Recognition Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dataset(\"FER2013\", root_dir=root_dir)\n",
    "preprocessor = get_preprocessor(\"FER2013\", root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"PCA\", \"AE\", \"ConvAE\", \"CAE\"]\n",
    "models = {}\n",
    "for name in names:\n",
    "    models[name] = get_model_for_dataset(\n",
    "        \"FER2013\", name, root_dir=root_dir, from_pretrained=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.random.choice(np.where(y == emotion)[0], 1)[0] for emotion in np.unique(y)]\n",
    "images = X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _ = plot_reconstructions(\n",
    "    models, images, preprocessor, width=48, height=48, channels=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dataset(\"MNIST\", root_dir=root_dir)\n",
    "preprocessor = get_preprocessor(\"MNIST\", root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"PCA\", \"AE\", \"ConvAE\", \"CAE\"]\n",
    "models = {}\n",
    "for name in names:\n",
    "    models[name] = get_model_for_dataset(\n",
    "        \"MNIST\", name, root_dir=root_dir, from_pretrained=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [np.random.choice(np.where(y == digit)[0], 1)[0] for digit in np.unique(y)]\n",
    "images = X[idx]\n",
    "fig, _ = plot_reconstructions(\n",
    "    models, images, preprocessor, width=28, height=28, channels=1, figsize=(5.91, 3.2)\n",
    ")  #\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.05)\n",
    "fig.savefig(\n",
    "    root_dir + \"/figures/reconstructions_mnist_pca_ae_convae_cae.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dataset(\"FashionMNIST\", root_dir=root_dir)\n",
    "preprocessor = get_preprocessor(\"FashionMNIST\", root_dir=root_dir)\n",
    "names = [\"PCA\", \"AE\", \"ConvAE\", \"CAE\"]\n",
    "models = {}\n",
    "for name in names:\n",
    "    models[name] = get_model_for_dataset(\n",
    "        \"FashionMNIST\", name, root_dir=root_dir, from_pretrained=True\n",
    "    )\n",
    "idx = [np.random.choice(np.where(y == digit)[0], 1)[0] for digit in np.unique(y)]\n",
    "images = X[idx]\n",
    "fig, _ = plot_reconstructions(\n",
    "    models, images, preprocessor, width=28, height=28, channels=1, figsize=(5.91, 3.35)\n",
    ")  #\n",
    "plt.subplots_adjust(wspace=0.0, hspace=0.1)\n",
    "fig.savefig(\n",
    "    root_dir + \"/figures/reconstructions_fashionmnist_pca_ae_convae_cae.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled Faces in the Wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_dataset(\"LfwPeople\", root_dir=root_dir)\n",
    "preprocessor = get_preprocessor(\"LfwPeople\", root_dir=root_dir)\n",
    "\n",
    "names = [\"PCA\", \"AE\", \"ConvAE\", \"CAE\"]\n",
    "models = {}\n",
    "for name in names:\n",
    "    models[name] = get_model_for_dataset(\n",
    "        \"LfwPeople\", name, root_dir=root_dir, from_pretrained=True\n",
    "    )\n",
    "\n",
    "images = resample(X, n_samples=8, stratify=y)\n",
    "fig, _ = plot_reconstructions(\n",
    "    models, images, preprocessor, width=47, height=62, channels=1, figsize=(5.91, 4)\n",
    ")  #\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "fig.savefig(\n",
    "    root_dir + \"/figures/reconstructions_lfw_pca_ae_convae_cae.png\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 10 2022, 16:20:20) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "6be29a84eb79a9d352d976989e4a991481101e9b7f1904e555bef89c75662f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
