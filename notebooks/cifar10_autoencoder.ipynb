{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from skorch import NeuralNet\n",
    "from drcomp.reducers import AutoEncoder\n",
    "from drcomp.autoencoder import AbstractAutoEncoder, Cifar10ConvAE\n",
    "import numpy as np\n",
    "from skorch.callbacks import Checkpoint, LRScheduler, ProgressBar, WandbLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"./cifar10_autoencoder.ipynb\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/storage/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(\n",
    "    root=\"../data\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_dataset.data.reshape(-1, 3, 32, 32).astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = LRScheduler(policy=\"ReduceLROnPlateau\")\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 100,\n",
    "}\n",
    "\n",
    "wandb_run = wandb.init(project=\"drcomp\", group=\"CIFAR10_Autoencoder\", reinit=True)\n",
    "wandb = WandbLogger(wandb_run)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoEncoder(\n",
    "    Cifar10ConvAE,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    max_epochs=config[\"epochs\"],\n",
    "    device=device,\n",
    "    callbacks=[lr_schedule, WandbLogger(wandb_run)],\n",
    ")\n",
    "model.fit(X)\n",
    "wandb_run.finish()\n",
    "with open(\"models/cifar10_autoencoder_contractive.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"models/cifar10_autoencoder_contractive.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = model.inverse_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6be29a84eb79a9d352d976989e4a991481101e9b7f1904e555bef89c75662f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
