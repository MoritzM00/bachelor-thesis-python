{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scienceplots\n",
    "from drcomp.autoencoder import FullyConnectedAE\n",
    "from drcomp.reducers import PCA, AutoEncoder\n",
    "from drcomp.utils.notebooks import get_dataset\n",
    "\n",
    "plt.style.use(\"science\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_autoencoder(input_size: int, intrinsic_dim: int, weight_decay: int):\n",
    "    base = FullyConnectedAE(\n",
    "        input_size=input_size,\n",
    "        intrinsic_dim=intrinsic_dim,\n",
    "        include_batch_norm=False,\n",
    "        tied_weights=False,\n",
    "        encoder_act_fn=nn.Identity,\n",
    "    )\n",
    "\n",
    "    return AutoEncoder(\n",
    "        base,\n",
    "        max_epochs=50,\n",
    "        lr=0.001,\n",
    "        batch_size=128,\n",
    "        weight_decay=weight_decay,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_weights(weights, intrinsic_dim, img_size, title=None, axs=None):\n",
    "    assert weights.shape == (\n",
    "        intrinsic_dim,\n",
    "        np.prod(img_size),\n",
    "    ), f\"Weights must be of shape (intrinsic_dim, np.prod(img_size)), but got {weights.shape}.\"\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(5.91, 5))\n",
    "    for ax, weight in zip(axs.flat, weights):\n",
    "        ax.imshow(weight.reshape(img_size), cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA, Autoencoder and the method implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_pca(X, intrinsic_dim):\n",
    "    pca = PCA(intrinsic_dim).fit(X)\n",
    "    loadings = pca.pca.components_\n",
    "    embedding = pca.transform(X)\n",
    "    return loadings, embedding\n",
    "\n",
    "\n",
    "def linear_autoencoder_weights(X, intrinsic_dim, weight_decay):\n",
    "    ae = get_linear_autoencoder(\n",
    "        X.shape[1], intrinsic_dim, weight_decay=weight_decay\n",
    "    ).fit(X)\n",
    "    weights = ae.module_.decoder[0].weight.data.numpy().T\n",
    "    embedding = ae.transform(X)\n",
    "    return weights, embedding\n",
    "\n",
    "\n",
    "def pca_by_autoencoder(X, weights):\n",
    "    U, s, _ = np.linalg.svd(weights.T, full_matrices=False)\n",
    "    U = U[:, np.argsort(s)[::-1]]\n",
    "    embedding = X @ U\n",
    "    return U.T, embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load FER dataset\n",
    "X, y = get_dataset(\"FER2013\", root_dir=\"..\")\n",
    "X_train = StandardScaler(with_mean=True, with_std=True).fit_transform(X)\n",
    "\n",
    "intrinsic_dim = 9\n",
    "img_size = (48, 48, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_analytical, embedding_pca = analytical_pca(X_train, intrinsic_dim)\n",
    "\n",
    "# unregularized autoencoder\n",
    "weights_unreg, embedding_ae_unreg = linear_autoencoder_weights(\n",
    "    X_train, intrinsic_dim, weight_decay=0\n",
    ")\n",
    "p_linear_unreg, embedding_pca_by_ae_unreg = pca_by_autoencoder(X_train, weights_unreg)\n",
    "\n",
    "# svd of the weights of a regularized autoencoder\n",
    "weights_reg, embedding_ae_reg = linear_autoencoder_weights(\n",
    "    X_train, intrinsic_dim, weight_decay=2e-4\n",
    ")\n",
    "p_linear, embedding_pca_by_ae = pca_by_autoencoder(X_train, weights_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [embedding_pca, embedding_pca_by_ae_unreg, embedding_pca_by_ae]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suptitles = [\"(a)\", \"(b)\", \"(c)\"]\n",
    "\n",
    "# plot the correlation matrices of the embeddings\n",
    "fig, axes = plt.subplots(1, 3, figsize=(5.91, 2.8))\n",
    "for i, (ax, embedding) in enumerate(zip(axes, embeddings)):\n",
    "    cov = np.cov(embedding, rowvar=False)\n",
    "    ax.imshow(cov, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.text(0.5, -0.2, suptitles[i], transform=ax.transAxes, ha=\"center\", fontsize=11)\n",
    "fig.savefig(\"../figures/covariance-matrices.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights\n",
    "fig = plt.figure(figsize=(5.91, 1.95))\n",
    "sfigs = fig.subfigures(1, 3)\n",
    "\n",
    "layout = (3, 3)\n",
    "axsL = sfigs[0].subplots(*layout)\n",
    "axsM = sfigs[1].subplots(*layout)\n",
    "axsR = sfigs[2].subplots(*layout)\n",
    "plot_weights(p_analytical, intrinsic_dim, img_size, axs=axsL)\n",
    "plot_weights(weights_unreg, intrinsic_dim, img_size, axs=axsM)\n",
    "plot_weights(p_linear, intrinsic_dim, img_size, axs=axsR)\n",
    "\n",
    "for sfig, suptitle in zip(sfigs, suptitles):\n",
    "    sfig.supxlabel(suptitle, fontsize=11)\n",
    "    sfig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "fig.savefig(\"../figures/weights-comparison.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6be29a84eb79a9d352d976989e4a991481101e9b7f1904e555bef89c75662f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
